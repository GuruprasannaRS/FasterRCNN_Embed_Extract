{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2479075,"sourceType":"datasetVersion","datasetId":1500356}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torchvision.models.detection import fasterrcnn_resnet50_fpn\nfrom torchvision.transforms import functional as F\nfrom PIL import Image\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom torchvision.models.detection.image_list import ImageList\nimport numpy as np\nimport pandas as pd\nimport os","metadata":{"execution":{"iopub.status.busy":"2023-12-18T02:59:37.416157Z","iopub.execute_input":"2023-12-18T02:59:37.417115Z","iopub.status.idle":"2023-12-18T02:59:40.917126Z","shell.execute_reply.started":"2023-12-18T02:59:37.417081Z","shell.execute_reply":"2023-12-18T02:59:40.916221Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"model = fasterrcnn_resnet50_fpn(pretrained=True)\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2023-12-18T02:59:40.919008Z","iopub.execute_input":"2023-12-18T02:59:40.919916Z","iopub.status.idle":"2023-12-18T02:59:42.390987Z","shell.execute_reply.started":"2023-12-18T02:59:40.919879Z","shell.execute_reply":"2023-12-18T02:59:42.390161Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n100%|██████████| 160M/160M [00:00<00:00, 271MB/s]  \n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"FasterRCNN(\n  (transform): GeneralizedRCNNTransform(\n      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n  )\n  (backbone): BackboneWithFPN(\n    (body): IntermediateLayerGetter(\n      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n      (relu): ReLU(inplace=True)\n      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (layer1): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): FrozenBatchNorm2d(256, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer2): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(512, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer3): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(1024, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (4): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (5): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer4): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(2048, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n    )\n    (fpn): FeaturePyramidNetwork(\n      (inner_blocks): ModuleList(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (2): Conv2dNormActivation(\n          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (layer_blocks): ModuleList(\n        (0-3): 4 x Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (extra_blocks): LastLevelMaxPool()\n    )\n  )\n  (rpn): RegionProposalNetwork(\n    (anchor_generator): AnchorGenerator()\n    (head): RPNHead(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n        )\n      )\n      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (roi_heads): RoIHeads(\n    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n    (box_head): TwoMLPHead(\n      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n    )\n    (box_predictor): FastRCNNPredictor(\n      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"def get_embeddings(model, image):\n    with torch.no_grad():\n        # Converting the PIL image into Pytorch tensor\n        image_tensor = F.to_tensor(image).unsqueeze(0)\n#         print(type(image_tensor))\n#         print('image are successfully converted into tensors')\n        \n        # Getting Predictions from the Model - It helped me to calculate the Number of Bounding Boxes\n        detections = model(image_tensor)\n        \n        # Extraction of Features from the Image\n        features = model.backbone(image_tensor)\n#         print(type(features))\n#         print(\"Features extracted Successfully\")\n\n#         if not isinstance(features, dict):\n#             raise ValueError(\"Backbone features are not in the expected dictionary format.\")\n\n        # Shape of Image tensors basically height and width\n        image_shape = image_tensor.shape[-2:] \n        image_list = ImageList(image_tensor, [image_shape])\n#         print(type(image_list))\n#         print('Tensors are convereted to Image list - which is the input for RPN)\n\n        # Passing into RPN\n        proposals, _ = model.rpn(image_list, features)\n#         print(type(proposals))\n#         print(\"Proposals Retrieved Successfully\")\n\n        # Region of Interest (ROI)\n        box_features = model.roi_heads.box_roi_pool(features, proposals,[image_shape] )\n#         print(type(box_features))\n\n        # Flattening\n        box_features = box_features.flatten(start_dim=1)\n        \n        # Embedding Extraction\n        box_embeddings = model.roi_heads.box_head(box_features)\n#         print(type(box_embeddings))\n\n        # Extract the Bouding Boxes from the detection\n        boxes = detections[0]['boxes']\n        num_boxes = boxes.shape[0]\n        print(num_boxes)\n        \n        return box_embeddings, num_boxes","metadata":{"execution":{"iopub.status.busy":"2023-12-18T02:59:42.391983Z","iopub.execute_input":"2023-12-18T02:59:42.392237Z","iopub.status.idle":"2023-12-18T02:59:42.400148Z","shell.execute_reply.started":"2023-12-18T02:59:42.392215Z","shell.execute_reply":"2023-12-18T02:59:42.399174Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Function to Process the Images like Applying embedding and saving the embeddings","metadata":{}},{"cell_type":"code","source":"def process_images(model, image_paths):\n    data = []\n    for image_path in image_paths:\n        image = Image.open(image_path)\n        embeddings, num_boxes = get_embeddings(model, image)\n        print(embeddings)\n        embeddings_filename = os.path.splitext(os.path.basename(image_path))[0] + '_embeddings.npy'\n        np.save(embeddings_filename, embeddings.cpu().numpy())\n        data.append({\n            'Image': os.path.basename(image_path),\n            'Num_BBoxes': num_boxes,\n            'Embedding_Size': embeddings.size(),\n            'Embeddings_File': embeddings_filename\n        })\n    return data","metadata":{"execution":{"iopub.status.busy":"2023-12-18T02:59:42.402751Z","iopub.execute_input":"2023-12-18T02:59:42.403027Z","iopub.status.idle":"2023-12-18T02:59:42.424368Z","shell.execute_reply.started":"2023-12-18T02:59:42.403003Z","shell.execute_reply":"2023-12-18T02:59:42.423510Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Function to get the paths","metadata":{}},{"cell_type":"code","source":"def get_image_paths(image_folder, limit=10):\n    image_paths = []\n    count = 0\n    for file_name in os.listdir(image_folder):\n        if file_name.endswith('.jpg'):\n            full_path = os.path.join(image_folder, file_name)\n            image_paths.append(full_path)\n            count += 1\n            if count >= limit:\n                break\n    return image_paths","metadata":{"execution":{"iopub.status.busy":"2023-12-18T02:59:42.425497Z","iopub.execute_input":"2023-12-18T02:59:42.425960Z","iopub.status.idle":"2023-12-18T02:59:42.436932Z","shell.execute_reply.started":"2023-12-18T02:59:42.425935Z","shell.execute_reply":"2023-12-18T02:59:42.436067Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"image_folder = '/kaggle/input/ms-coco-dataset/train2014/train2014'\nimage_paths = get_image_paths(image_folder)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T02:59:42.438045Z","iopub.execute_input":"2023-12-18T02:59:42.438332Z","iopub.status.idle":"2023-12-18T02:59:43.218244Z","shell.execute_reply.started":"2023-12-18T02:59:42.438303Z","shell.execute_reply":"2023-12-18T02:59:43.217241Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"image_data = process_images(model, image_paths)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T02:59:43.219542Z","iopub.execute_input":"2023-12-18T02:59:43.219858Z","iopub.status.idle":"2023-12-18T03:00:25.818859Z","shell.execute_reply.started":"2023-12-18T02:59:43.219832Z","shell.execute_reply":"2023-12-18T03:00:25.817920Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"52\ntensor([[0.0000, 1.4023, 0.0000,  ..., 0.4037, 0.0000, 0.0000],\n        [0.6489, 0.5089, 0.6012,  ..., 0.0000, 0.0000, 2.1589],\n        [1.1482, 0.3465, 0.1313,  ..., 0.0000, 0.0000, 1.8975],\n        ...,\n        [0.0000, 0.0000, 0.0325,  ..., 0.0160, 1.8877, 0.3443],\n        [0.0000, 0.0000, 0.2788,  ..., 0.4492, 1.5149, 0.4678],\n        [0.0000, 0.4755, 0.0000,  ..., 0.0000, 2.1681, 0.5031]])\n3\ntensor([[0.0336, 0.1411, 0.2680,  ..., 0.0000, 0.0000, 1.3485],\n        [0.0000, 0.0000, 0.2409,  ..., 0.0000, 0.0000, 0.6287],\n        [0.0205, 0.0000, 0.6677,  ..., 0.0000, 0.8458, 1.0905],\n        ...,\n        [0.0000, 0.6868, 0.7615,  ..., 0.0000, 0.8355, 0.6601],\n        [0.0000, 0.8652, 0.3970,  ..., 0.0000, 1.8524, 0.4940],\n        [0.0000, 0.2949, 0.0000,  ..., 0.0000, 0.4014, 1.2985]])\n100\ntensor([[0.4606, 1.8814, 0.0000,  ..., 0.0000, 0.0665, 0.0000],\n        [0.0000, 0.0000, 0.4352,  ..., 0.0000, 0.0000, 0.0000],\n        [0.6684, 0.5941, 0.0480,  ..., 0.0000, 0.0000, 0.0000],\n        ...,\n        [1.0644, 0.0000, 0.7369,  ..., 0.0000, 1.1043, 0.0000],\n        [0.0000, 1.0691, 0.0000,  ..., 0.2631, 0.9574, 0.6552],\n        [0.0000, 0.6736, 0.2557,  ..., 0.0000, 1.4244, 0.9388]])\n16\ntensor([[0.0000, 0.9376, 0.7613,  ..., 0.0000, 0.0000, 2.7671],\n        [0.5715, 0.0000, 0.8062,  ..., 0.0000, 0.1956, 1.8574],\n        [0.2635, 1.6033, 0.0000,  ..., 0.0000, 0.0000, 3.8749],\n        ...,\n        [0.0000, 0.8355, 0.0000,  ..., 0.0000, 1.8855, 0.3465],\n        [0.0000, 0.0448, 0.3105,  ..., 0.0000, 0.6137, 1.1790],\n        [0.0000, 0.3354, 0.0308,  ..., 0.0000, 1.7847, 1.4391]])\n23\ntensor([[0.1669, 0.5099, 0.0000,  ..., 0.0000, 0.0000, 0.8078],\n        [0.3385, 1.8911, 0.0000,  ..., 0.0000, 0.2955, 0.0000],\n        [0.3150, 0.2766, 0.0000,  ..., 0.8882, 0.0000, 0.8061],\n        ...,\n        [0.1026, 0.9230, 0.0000,  ..., 0.0000, 1.4228, 0.0000],\n        [0.1237, 0.6851, 0.6500,  ..., 0.0000, 2.0833, 0.9057],\n        [0.0000, 1.7758, 0.5648,  ..., 0.0000, 1.1743, 0.2593]])\n38\ntensor([[1.5917, 1.3532, 0.8511,  ..., 0.0000, 0.0000, 1.3573],\n        [0.5004, 1.2677, 0.5590,  ..., 0.0000, 0.0000, 0.0000],\n        [0.1534, 0.6686, 0.8987,  ..., 0.0000, 0.0000, 0.7557],\n        ...,\n        [0.0000, 0.8078, 0.0000,  ..., 0.0000, 0.0000, 0.3770],\n        [0.0000, 0.0000, 0.6172,  ..., 0.0000, 1.4297, 0.3538],\n        [0.0000, 0.4554, 0.0000,  ..., 0.0000, 1.3227, 0.5332]])\n49\ntensor([[0.0000, 0.9251, 0.0000,  ..., 0.0000, 0.1451, 0.0000],\n        [0.0000, 0.0000, 0.5739,  ..., 0.0000, 0.0000, 0.0000],\n        [0.0000, 0.7848, 0.2818,  ..., 0.0000, 0.0000, 0.1174],\n        ...,\n        [0.0000, 0.0000, 0.0095,  ..., 0.0000, 1.0140, 0.0000],\n        [0.0000, 1.2863, 0.0000,  ..., 0.0000, 0.2799, 0.7246],\n        [0.0000, 0.9363, 0.9592,  ..., 0.0000, 1.2584, 0.0000]])\n45\ntensor([[2.0833, 0.5952, 0.2703,  ..., 0.0000, 0.0000, 1.9980],\n        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n        [0.0000, 0.3790, 0.0536,  ..., 0.0000, 0.0000, 0.6691],\n        ...,\n        [0.7185, 0.4751, 1.1250,  ..., 0.0000, 0.0000, 0.2434],\n        [0.0427, 0.7789, 0.0000,  ..., 0.0000, 0.0000, 1.7490],\n        [0.0468, 0.2339, 0.0000,  ..., 0.0000, 0.8085, 0.5943]])\n100\ntensor([[1.2768, 1.2160, 0.4297,  ..., 0.0000, 0.0000, 0.2877],\n        [0.0000, 1.0463, 0.0000,  ..., 0.3466, 0.0000, 0.5654],\n        [1.0544, 0.4741, 0.5298,  ..., 0.0000, 0.0000, 0.0000],\n        ...,\n        [0.7300, 1.3206, 1.1049,  ..., 0.0000, 0.0000, 0.7027],\n        [0.3390, 0.4180, 0.7167,  ..., 0.0000, 0.9757, 1.4102],\n        [0.5341, 0.9362, 1.1129,  ..., 0.0000, 1.1920, 0.9676]])\n9\ntensor([[0.6211, 1.2390, 0.3808,  ..., 0.0000, 0.0000, 0.3668],\n        [0.8923, 1.4367, 0.8390,  ..., 0.0000, 0.8047, 0.6814],\n        [0.3158, 0.8319, 0.0470,  ..., 0.0000, 0.5076, 0.1311],\n        ...,\n        [0.0000, 1.3498, 0.0000,  ..., 0.0000, 0.2080, 0.0000],\n        [0.0000, 0.3269, 0.6807,  ..., 0.0000, 1.6985, 0.0000],\n        [0.0000, 0.9756, 0.3485,  ..., 0.0000, 2.2043, 1.2131]])\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.DataFrame(image_data)\ndf","metadata":{"execution":{"iopub.status.busy":"2023-12-18T03:00:25.820123Z","iopub.execute_input":"2023-12-18T03:00:25.820448Z","iopub.status.idle":"2023-12-18T03:00:25.843964Z","shell.execute_reply.started":"2023-12-18T03:00:25.820422Z","shell.execute_reply":"2023-12-18T03:00:25.843000Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                             Image  Num_BBoxes Embedding_Size  \\\n0  COCO_train2014_000000263229.jpg          52   (1000, 1024)   \n1  COCO_train2014_000000381595.jpg           3   (1000, 1024)   \n2  COCO_train2014_000000147733.jpg         100   (1000, 1024)   \n3  COCO_train2014_000000559395.jpg          16   (1000, 1024)   \n4  COCO_train2014_000000374072.jpg          23   (1000, 1024)   \n5  COCO_train2014_000000233539.jpg          38    (974, 1024)   \n6  COCO_train2014_000000213863.jpg          49   (1000, 1024)   \n7  COCO_train2014_000000471409.jpg          45   (1000, 1024)   \n8  COCO_train2014_000000487632.jpg         100   (1000, 1024)   \n9  COCO_train2014_000000242092.jpg           9   (1000, 1024)   \n\n                              Embeddings_File  \n0  COCO_train2014_000000263229_embeddings.npy  \n1  COCO_train2014_000000381595_embeddings.npy  \n2  COCO_train2014_000000147733_embeddings.npy  \n3  COCO_train2014_000000559395_embeddings.npy  \n4  COCO_train2014_000000374072_embeddings.npy  \n5  COCO_train2014_000000233539_embeddings.npy  \n6  COCO_train2014_000000213863_embeddings.npy  \n7  COCO_train2014_000000471409_embeddings.npy  \n8  COCO_train2014_000000487632_embeddings.npy  \n9  COCO_train2014_000000242092_embeddings.npy  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image</th>\n      <th>Num_BBoxes</th>\n      <th>Embedding_Size</th>\n      <th>Embeddings_File</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>COCO_train2014_000000263229.jpg</td>\n      <td>52</td>\n      <td>(1000, 1024)</td>\n      <td>COCO_train2014_000000263229_embeddings.npy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>COCO_train2014_000000381595.jpg</td>\n      <td>3</td>\n      <td>(1000, 1024)</td>\n      <td>COCO_train2014_000000381595_embeddings.npy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>COCO_train2014_000000147733.jpg</td>\n      <td>100</td>\n      <td>(1000, 1024)</td>\n      <td>COCO_train2014_000000147733_embeddings.npy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>COCO_train2014_000000559395.jpg</td>\n      <td>16</td>\n      <td>(1000, 1024)</td>\n      <td>COCO_train2014_000000559395_embeddings.npy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>COCO_train2014_000000374072.jpg</td>\n      <td>23</td>\n      <td>(1000, 1024)</td>\n      <td>COCO_train2014_000000374072_embeddings.npy</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>COCO_train2014_000000233539.jpg</td>\n      <td>38</td>\n      <td>(974, 1024)</td>\n      <td>COCO_train2014_000000233539_embeddings.npy</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>COCO_train2014_000000213863.jpg</td>\n      <td>49</td>\n      <td>(1000, 1024)</td>\n      <td>COCO_train2014_000000213863_embeddings.npy</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>COCO_train2014_000000471409.jpg</td>\n      <td>45</td>\n      <td>(1000, 1024)</td>\n      <td>COCO_train2014_000000471409_embeddings.npy</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>COCO_train2014_000000487632.jpg</td>\n      <td>100</td>\n      <td>(1000, 1024)</td>\n      <td>COCO_train2014_000000487632_embeddings.npy</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>COCO_train2014_000000242092.jpg</td>\n      <td>9</td>\n      <td>(1000, 1024)</td>\n      <td>COCO_train2014_000000242092_embeddings.npy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.to_excel('data_emebeddings.xlsx', index=False)\nprint(\"Data saved\")","metadata":{"execution":{"iopub.status.busy":"2023-12-18T03:00:25.845253Z","iopub.execute_input":"2023-12-18T03:00:25.845876Z","iopub.status.idle":"2023-12-18T03:00:26.137247Z","shell.execute_reply.started":"2023-12-18T03:00:25.845830Z","shell.execute_reply":"2023-12-18T03:00:26.136352Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Data saved\n","output_type":"stream"}]}]}